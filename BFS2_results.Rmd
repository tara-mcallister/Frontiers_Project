---
title: "Frontiers paper"
author: "Tara McAllister Byun and Heather Campbell"
date: "July 1, 2016"
output: html_document
---
```{r, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
########################################
#LOAD PACKAGES
########################################
rm(list=ls())
library(plotrix)
library(plyr)
library(fields)
library(reshape2)
library(lme4)
library(ggplot2)
library(plyr)
library(dplyr)
library(car)
library(gridExtra)
library(ppcor)
library(SCRT)
library(httpuv)  
library(caTools)
library(magrittr)
library(tidyr)
```

```{r, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
################################################################
#WARNING!!!!!   THIS CODE LOADS AND CLEANS DATA 
###Warning!! This code is currently not active because it's not writing a version of new clean data!!!!!!
##Need to uncomment the write.csv line if you want this code to have an effect!
#################################################################

data  = read.csv("BFS2_trials_summarized", sep="\t", header=T)
#str(data)
#data$X.1 <- NULL
#dim(data)
#which(is.na(data$mean))

#Subject as factor
data$subject <- as.factor(data$subject)

#Create a session column
data$sessioncode <- data$Filename
data$study <- as.factor(sapply(strsplit(as.character(data$sessioncode), "\\_"), function(x) x[[1]]))
data$session <- as.factor(sapply(strsplit(as.character(data$sessioncode), "\\_"), function(x) x[[3]]))
#levels(data$session)

#Cleanup: There is inconsistency in whether Tx is written Tx or TX
#fixme <- data[which(grepl("TX", data$session)==T),]
data$session <- recode(data$session, c("'Tx3'='TX3'"))
data$session <- recode(data$session, c("'tx11'='TX11'"))
data$session <- recode(data$session, c("'tx12'='TX12'"))
data$session <- recode(data$session, c("'Tx13'='TX13'"))
data$session <- recode(data$session, c("'Tx17'='TX17'"))
data$session <- recode(data$session, c("'Tx18'='TX18'"))
data$session <- recode(data$session, c("'Tx19'='TX19'"))
data$session <- recode(data$session, c("'Tx20'='TX20'"))
#levels(data$session)

#Create a session type column 
data$sessiontype <- as.factor(substring(data$session,1,2))  
#levels(data$sessiontype)

#Create condition and prepost columns
#Previously these were all starting out as NA; info was filled in to the condition and prepost
#columns for treatment sessions only (not probe sessions). However, the NAs were causing problems,
#so now the default coding is "PROBE."
data$condition <- "PROBE"
data$prepost <- "PROBE"

#Fill in condition and pre/post columns for TREATMENT DATA only
dataBL <- droplevels(data[which(data$sessiontype=="BL"),])
dataMN <- droplevels(data[which(data$sessiontype=="MN"),])
dataMP <- droplevels(data[which(data$sessiontype=="MP"),])
dataTX <- droplevels(data[which(data$sessiontype=="TX"),])

dataTX$prepost <- sapply(strsplit(as.character(dataTX$sessioncode), "\\_"), function(x) x[[4]])
dataTX$condition <- as.factor(sapply(strsplit(as.character(dataTX$sessioncode), "\\_"), function(x) x[[5]]))

#Use tables to check if cleanup is needed
#table(dataTX$prepost)
#table(dataTX$condition)

#Argh, some of the TX sessions have "Probe" or "pre/post" where they ought to have BF/TRAD
#set aside data that don't need changing
gooddata <- filter(dataTX, condition=="BF"|condition=="Trad")
#dim(gooddata)
#Pull out the data to change
checkme <- filter(dataTX, condition!="BF"&condition!="Trad")
#dim(checkme)
#Pull out the subset with "pre" or "post" instead of Trad/BF
prepost <- filter(checkme, condition=="post"|condition=="pre")
#All of the pre/post errors are from one session, so it's easy to fix:
prepost$prepost <- prepost$condition
prepost$condition <- "Trad"
#Pull out the subset with "Probe"
probe <- filter(checkme, condition=="Probe")
#These are also all from one session. According to the calendar, this was a BF session.
probe$condition <- "BF"
#The remaining subset has no _ between BF and word
nounderscore <- checkme[which(grepl("BF", checkme$condition)==T),]
nounderscore$condition <- as.factor(substring(nounderscore$condition,1,2))  
dataTX <- droplevels(rbind(gooddata, prepost, probe, nounderscore))
#table(dataTX$condition)

#Now fix the prepost column
#table(dataTX$prepost)
#Need to standardize capitalization
dataTX$prepost <- recode(dataTX$prepost, c("'post'='Post'"))
dataTX$prepost <- recode(dataTX$prepost, c("'pre'='Pre'"))

#Rebind all
data <- rbind(dataBL, dataMP, dataMN, dataTX)
data$session <- as.factor(data$session)
data$condition <- as.factor(data$condition)
data$prepost <- as.factor(data$prepost)
#levels(data$condition)
#levels(data$prepost)

#Add demographic info
demog = read.csv("BFS2_demog.csv")
demog$subject <- as.factor(demog$subject)
data <- left_join(data, demog, by="subject")
data$subject <- as.factor(data$subject)
#str(data)

#Make session an ordered factor
#levels(data$session)
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   
#rewrite with new participant names
#Uncomment this if you want to generate the summarized data file anew
#write.csv(data, "clean_data.csv")
```

##Individual results: Effect sizes

```{r, echo=FALSE, fig.width=7, fig.height=2,message=FALSE, warning=FALSE}
#################################################################
#THIS CODE CALCULATES EFFECT SIZES
#################################################################
data <- read.csv("clean_data.csv")

#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)
#Need to re-set ordered factors
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5",
        "TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10","MP1","MP2","MP3",
        "TX11","TX12","TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   

#This code creates an option to examine only the primary probe words 
#and exclude less frequently occurring generalization items
#Note how these categories are defined: primary means probed in BLMN and PREPOST,
#"generalization" means probed in BLMN only. 
#All are untreated (i.e. not words used as targets during treatment)
#Determine which words are BLMN only and which are shared BLMN/PREPOST
  #  length(levels(data$word))
   tab2 = as.data.frame(plyr::count(data,"word"))
    #plot(tab2$freq)
    #items occurring over 300 times are shared BLMN/PREPOST
    #and the items occurring under 200 times are BLMN only
    both <- droplevels(tab2[which(tab2$freq>300),])
    primary <- levels(both$word)
    only <- droplevels(tab2[which(tab2$freq<200),])
    generalization <- levels(only$word)

#Option to reduce to only primary words
#You can ignore it if you are including all words
    primarywords <- droplevels(data[which(data$word%in%primary),])
  #  head(primarywords)
  #  levels(primarywords$word)
    primarywords$word_type <- "primary"
    generalizationwords <- droplevels(data[which(data$word%in%generalization),])
  #  head(generalizationwords)
  #  levels(generalizationwords$word)
    generalizationwords$word_type <- "generalization"
    #Only uncomment this if you want to exclude generalization words
    #data <- primarywords

#Calculate average n of tokens per session
#str(data)
#levels(data$session)

tab = plyr::count(data, c("subject","session","prepost"))
#tab <- as.data.frame(tab)
BLMN <- tab[which(tab$prepost=="PROBE"),]
PREPOST <- tab[which(tab$prepost!="PROBE"),]
mBLMN <- mean(BLMN$freq)
sdBLMN <- sd(BLMN$freq)
mPREPOST <- mean(PREPOST$freq)
sdPREPOST <- sd(PREPOST$freq)

tx1 <- data
#str(tx1)
Children <- levels(tx1$subject)

#True baseline points
#For each child, calculate the percent of "yes" votes out of total votes in each session
#And average across sessions
bl1 <- droplevels(subset(tx1, sessiontype=="BL"))
nbl <- c()
bl1_sum <- c()
bl1_total <- c()
bl1_perc <- c()
blall_perc <- c()  ; blall_names <- c() ; blall_sd <- c()   #add these one for BL stabilility measures
bl1_m <- c()
bl1_sd <-c()
for (i in seq_along(Children)){
  child <- droplevels(subset(bl1, subject==Children[i],))
  nbl[i] <- length(levels(child$session))
  bl1_sum <- tapply(child$correct, child$session, sum, na.rm=TRUE)
  bl1_total <- tapply(child$total, child$session, sum, na.rm=TRUE)
  bl1_perc <- bl1_sum*100/bl1_total
  blall_perc <- c(blall_perc, bl1_perc)   #add this one for BL stabilility measures
  blall_names <- c(blall_names, rep(Children[i], each= nbl[i]))  
  bl1_m[i] <- mean(bl1_perc)
  bl1_sd[i] <- sd(bl1_perc)
  blall_sd <- c(blall_sd, rep(bl1_sd[i], each= nbl[i]))  
}

#Midpoints
#For each child, calculate the percent of "yes" votes out of total votes in each session
#And average across sessions
mp1 <- droplevels(subset(tx1, sessiontype=="MP"))
nmp <- c()
mp1_sum <- c()
mp1_total <- c()
mp1_perc <- c()
mp1_m <- c()
mp1_sd <-c()
for (i in seq_along(Children)){
  child <- droplevels(subset(mp1, subject==Children[i],))
  nmp[i] <- length(levels(child$session))
  mp1_sum <- tapply(child$correct, child$session, sum, na.rm=TRUE)
  mp1_total <- tapply(child$total, child$session, sum, na.rm=TRUE)
  mp1_perc <- mp1_sum*100/mp1_total
  mp1_m[i] <- mean(mp1_perc)
  mp1_sd[i] <- sd(mp1_perc)
}

#True maintenance points
mn1 <- subset(tx1, sessiontype=="MN")
nmn <- c()
mn1_sum <- c()
mn1_total <- c()
mn1_perc <- c()
mn1_m <- c()
mn1_sd <-c()
for (i in seq_along(Children)){
  child <- droplevels(subset(mn1, subject==Children[i],))
  nmn[i] <- length(levels(child$session))
  mn1_sum <- tapply(child$correct, child$session, sum, na.rm=TRUE)
  mn1_total <- tapply(child$total, child$session, sum, na.rm=TRUE)
  mn1_perc <- mn1_sum*100/mn1_total
  mn1_m[i] <- mean(mn1_perc)
  mn1_sd[i] <- sd(mn1_perc)
}

#Effect size 1: BL to MP
#Calculate SD pooled across baseline and MP phases
pooled1a <- sqrt(((nbl-1)*(bl1_sd^2) + (nmp-1)*(mp1_sd^2))/(nbl+nmp-2))
    #Alternative using magrittr syntax
    pooled1 <- ((nbl-1)*(bl1_sd^2)) %>%
      add((nmp-1)*(mp1_sd^2)) %>%
      divide_by(nbl+nmp-2) %>%
      raise_to_power(1/2)
    #Check that they yield the same output
    #pooled1a==pooled1
#Effect size = mean level difference divided by pooled SD
ESPhase1 <- (mp1_m - bl1_m)/pooled1

#Effect size 2: MP to MN
#Calculate SD pooled across MP and MN phases
pooled2a <- sqrt(((nmp-1)*(mp1_sd^2) + (nmn-1)*(mn1_sd^2))/(nmp+nmn-2))
    #Alternative using magrittr syntax
    pooled2 <- ((nmp-1)*(mp1_sd^2)) %>%
      add((nmn-1)*(mn1_sd^2)) %>%
      divide_by(nmp+nmn-2) %>%
      raise_to_power(1/2)
    #Check that they yield the same output
    #pooled2a==pooled2
#Effect size = mean level difference divided by pooled SD
ESPhase2 <- (mn1_m - mp1_m)/pooled2

#Effect size 3: BL to MN
#Calculate SD pooled across baseline and MN phases
pooled3a <- sqrt(((nbl-1)*(bl1_sd^2) + (nmn-1)*(mn1_sd^2))/(nbl+nmn-2))
    #Alternative using magrittr syntax
    pooled3 <- ((nbl-1)*(bl1_sd^2)) %>%
      add((nmn-1)*(mn1_sd^2)) %>%
      divide_by(nbl+nmn-2) %>%
      raise_to_power(1/2)
    #Check that they yield the same output
    #pooled3a==pooled3
#Effect size = mean level difference divided by pooled SD
ESall <- (mn1_m - bl1_m)/pooled3

bl1_m <- round(bl1_m, digits=2)
bl1_sd <- round(bl1_sd, digits=2)
mp1_m <- round(mp1_m, digits=2)
mp1_sd <- round(mp1_sd, digits=2)
mn1_m <- round(mn1_m, digits=2)
mn1_sd <- round(mn1_sd, digits=2)
pooled1 <- round(pooled1, digits=2)
ESPhase1 <- round(ESPhase1, digits=2)
pooled2 <- round(pooled2, digits=2)
ESPhase2 <- round(ESPhase2, digits=2)
pooled3 <- round(pooled3, digits=2)
ESall <- round(ESall, digits=2)

data1 <- data.frame(Children, bl1_m, bl1_sd,mp1_m, mp1_sd, mn1_m, mn1_sd, pooled1, ESPhase1, pooled2, ESPhase2, pooled3, ESall)
colnames(data1)[1] <- "subject" 
#str(data1)

#Add demographic info
demog  = read.csv("BFS2_demog.csv", header=T)
demog$subject <- as.factor(demog$subject)
data2 <- left_join(data1, demog, by="subject")
data2$subject <- as.factor(data2$subject)
#str(data2)

#change psuedonyms to pseudo-pseudonyms
data2$originalpseudonym <- data2$subject
data2$subject <- mapvalues(data2$originalpseudonym, from = c("Adrian", "Brooklyn", "Connor", "Emily", 
                                                           "Emma", "Gabriel",  "Hailey", "Hannah", 
                                                           "Jack", "Liam", "Madison"), 
                          to = c("Aiden", "Bryce", "Cooper", "Erica", 
                                 "Ella", "Gregory",  "Holly", "Harper", 
                                 "Jason", "Landon", "Mason"))


#Code by treatment type
TRAD1 <- droplevels(subset(data2, tx_order=="TRAD_BF"))
TRAD1$ES_TRAD <- TRAD1$ESPhase1
TRAD1$ES_BF <- TRAD1$ESPhase2

BF1 <- droplevels(subset(data2, tx_order=="BF_TRAD"))
BF1$ES_TRAD <- BF1$ESPhase2
BF1$ES_BF <- BF1$ESPhase1

data3 <- rbind(TRAD1, BF1) 
data3short <- data3[,1:13]
data3short$pooled1 <- NULL
data3short$pooled2 <- NULL
data3short$pooled3 <- NULL

#Diff in effect size between BF and TRAD conditions
#Putting BF first because hypothesized to have larger effect
data3$BF_advantage <- data3$ES_BF - data3$ES_TRAD

#Diff in effect size between first and second phases
#Putting Phase 2 first because hypothesized to show cumulative effect
data3$order_effect <- data3$ESPhase2 - data3$ESPhase1

######################################################
```

Effect sizes representing change in $\hat{p}_{correct}$ for the treated variant, vocalic /r/, are reported for all participants in Table 3. The first column shows participants' mean $\hat{p}_{correct}$ in the baseline period, averaged across all vocalic /r/ items from all baseline sessions. The second column shows the equivalent mean across the three midpoint sessions, and the third shows the three maintenance sessions. The next three columns report three standardized effect sizes: ES~Phase1~ compares baseline versus midpoint scores, *ES~Phase2~* compares midpoint versus maintenance scores, and *ES~All~* compares baseline versus maintenance, reflecting overall gains across both phases of treatment. Participants are blocked by the order in which they received treatment (traditional-first or biofeedback-first). The effect sizes in Table 3 show a wide range of variability in overall response to treatment across individuals. Averaging effect sizes across all participants yields a mean of `r round(mean(data3$ESall), digits=2)`, suggesting that on average, participants' response to the combined biofeedback and traditional treatment package was positive and exceeded the minimum value considered clinically significant. Individual patterns of response will be examined in detail in the next section. 


```{r, echo=FALSE, fig.width=7, fig.height=2,message=FALSE, warning=FALSE}

library(knitr)
kable(data3short)  
```

```{r, echo=FALSE}
########## begin BL stability measures
##baseline stability:  Comment on baseline stability: Which participants met the criterion of <10% mean session-to-session variability over the baseline interval? Which participants have demonstrations of noneffect in the baseline phase?**
BL_sessions <- data.frame(Subject = blall_names, session = as.numeric(as.factor(names(blall_perc))), percent = blall_perc, sd = blall_sd)
BL_sessions$Subject <- mapvalues(BL_sessions$Subject, from = c("Adrian", "Brooklyn", "Connor", "Emily", 
                                                           "Emma", "Gabriel",  "Hailey", "Hannah", 
                                                           "Jack", "Liam", "Madison"), 
                          to = c("Aiden", "Bryce", "Cooper", "Erica", 
                                 "Ella", "Gregory",  "Holly", "Harper", 
                                 "Jason", "Landon", "Mason"))

#Calculate differences btw BLs among those with 3 BLs:  Adrian, Brooklyn, Emily, Hailey, Jack
BL_sessions_3 <- subset(BL_sessions, BL_sessions$Subject == "Aiden" | BL_sessions$Subject == "Bryce" | 
                          BL_sessions$Subject == "Erica" | BL_sessions$Subject == "Holly" | BL_sessions$Subject == "Jason")

BL_diffs_3 <- c()
for (i in c("Aiden", "Bryce", "Erica", "Holly", "Jason")){
  BL_diffs_3 <- c(BL_diffs_3, c(NA, 
      BL_sessions_3$percent[BL_sessions_3$Subject == i & BL_sessions_3$session == 2] -
          BL_sessions_3$percent[BL_sessions_3$Subject == i & BL_sessions_3$session == 1], 
      BL_sessions_3$percent[BL_sessions_3$Subject == i & BL_sessions_3$session == 3] -
          BL_sessions_3$percent[BL_sessions_3$Subject == i & BL_sessions_3$session == 2]))
}
BL_sessions_3$diff <- abs(BL_diffs_3)

#Calculate differences btw BLs among those with 4 BLs:  Connor, Gabriel, Hannah, Liam
BL_sessions_4 <- subset(BL_sessions, BL_sessions$Subject == "Cooper" | BL_sessions$Subject == "Gregory" |
           BL_sessions$Subject == "Harper" | BL_sessions$Subject == "Landon")

BL_diffs_4 <- c()
for (i in c("Cooper", "Gregory", "Harper", "Landon")){
  BL_diffs_4 <- c(BL_diffs_4, c(NA, 
      BL_sessions_4$percent[BL_sessions_4$Subject == i & BL_sessions_4$session == 2] -
          BL_sessions_4$percent[BL_sessions_4$Subject == i & BL_sessions_4$session == 1],
      BL_sessions_4$percent[BL_sessions_4$Subject == i & BL_sessions_4$session == 3] -
          BL_sessions_4$percent[BL_sessions_4$Subject == i & BL_sessions_4$session == 2],
      BL_sessions_4$percent[BL_sessions_4$Subject == i & BL_sessions_4$session == 4] -
          BL_sessions_4$percent[BL_sessions_4$Subject == i & BL_sessions_4$session == 3]))
}
BL_sessions_4$diff <- abs(BL_diffs_4)

#Calculate differences btw BLs among those with 5 BLs:  Emma, Madison
BL_sessions_5 <- subset(BL_sessions, BL_sessions$Subject == "Ella" | BL_sessions$Subject == "Mason")

BL_diffs_5 <- c()
for (i in c("Ella", "Mason")){
  BL_diffs_5 <- c(BL_diffs_5, c(NA, 
      BL_sessions_5$percent[BL_sessions_5$Subject == i & BL_sessions_5$session == 2] -
          BL_sessions_5$percent[BL_sessions_5$Subject == i & BL_sessions_5$session == 1],
      BL_sessions_5$percent[BL_sessions_5$Subject == i & BL_sessions_5$session == 3] -
          BL_sessions_5$percent[BL_sessions_5$Subject == i & BL_sessions_5$session == 2],
      BL_sessions_5$percent[BL_sessions_5$Subject == i & BL_sessions_5$session == 4] -
          BL_sessions_5$percent[BL_sessions_5$Subject == i & BL_sessions_5$session == 3],
      BL_sessions_5$percent[BL_sessions_5$Subject == i & BL_sessions_5$session == 5] -
          BL_sessions_5$percent[BL_sessions_5$Subject == i & BL_sessions_5$session == 4]))
}
BL_sessions_5$diff <- abs(BL_diffs_5)

#To calculate mean session-to-session change: calculate the difference for each pair of adjacent sessions (score[session N+1] - score[session N]), sum across all pairs of adjacent sessions, divided by the total number of pairs
BL_sessions <- rbind(BL_sessions_3, BL_sessions_4, BL_sessions_5)

sum_diff_3 <- c() ; mean_session_to_session_change_3 <- c()
for (i in c("Aiden", "Bryce", "Erica", "Holly", "Jason")){
    sum_diff_3[i] <- sum(BL_sessions$diff[BL_sessions$Subject == i][-1])
    mean_session_to_session_change_3[i] <- sum_diff_3[i]/2    #divide by total number of pairs
}

sum_diff_4 <- c() ; mean_session_to_session_change_4 <- c()
for (i in c("Cooper", "Gregory", "Harper", "Landon")){
    sum_diff_4[i] <- sum(BL_sessions$diff[BL_sessions$Subject == i][-1])
    mean_session_to_session_change_4[i] <- sum_diff_4[i]/3    #divide by total number of pairs
}

sum_diff_5 <- c() ; mean_session_to_session_change_5 <- c()
for (i in c("Ella", "Mason")){
    sum_diff_5[i] <- sum(BL_sessions$diff[BL_sessions$Subject == i][-1])
    mean_session_to_session_change_5[i] <- sum_diff_5[i]/4    #divide by total number of pairs
  }

#1. Mean session-to-session change: calculate the difference for each pair of adjacent sessions (score[session N+1] - score[session N]), sum across all pairs of adjacent sessions, divided by the total number of pairs
#round(c(mean_session_to_session_change_3, mean_session_to_session_change_4, mean_session_to_session_change_5), digits=2) #1 #Answer: All <10 percentage points. Emma, Adrian & Liam stand out as highest.

#2. Identify any outliers: Points > 2 SD away from the mean across the baseline interval
high <- c(); low <- c()
for (i in data3$subject){
  i <- subset(BL_sessions, Subject == i)
  high <- rbind(high, subset(i, i$percent > (mean(i$percent) + 2*sd(i$percent))))
  low <- rbind(low, subset(i, i$percent < (mean(i$percent) - 2*sd(i$percent))))
}
outliers <- rbind(high, low)  #2 answer:  no outliers


#3. Identify any baseline phases that end on a rising trend: last 3 datapoints show a monotonic increase with a magnitude that is greater than the baseline SD
#originally interpreted as session-session rise exceeding sd:
rising_session <- c()
for (i in data3$subject){
  i <- subset(BL_sessions, Subject == i)
  rising_session <- rbind(rising_session, subset(i, i$diff > i$sd))
}
#rising_session   #3a answer:  Ella & Harper showed last 3 session diff greater than sd

#does the sum of the rise in final 3 sessions exceed the sd?
rising <- c()
for (i in data3$subject){
  i <- subset(BL_sessions, Subject == i)
  i <- subset(i, session == tail(sort(i$session), 3)[1] | session == tail(sort(i$session), 3)[2] | session == tail(sort(i$session), 3)[3])
  rising <- rbind(rising, subset(i, (max(i$percent) - min(i$percent)) > i$sd))
}
#rising  #3b:  Yes, for all participants, the max-min diff in the 3 final sessions exceeds the sd, only for Adrian and Emma does it appear to be a monotonic increase

########## end BL stability measures
```

##Individual results: Visual inspection

Figures 2-4 represent each participant's pattern of change in accuracy ($\hat{p}_{correct}$) over time, which can be visually inspected to corroborate the effect sizes reported in Table 3. Discussion of differences in relative response to biofeedback versus traditional treatment will be deferred until the next section, which reports the results of an across-subjects comparison via logistic mixed model. In the single-subject plots in Figures 2-4, each child is represented by two boxes. The upper box reflects performance on probe measures administered before and after each biofeedback treatment session and additionally reports probe scores from the pre-treatment baseline and post-treatment maintenance periods (shaded gray). The lower box reflects performance during traditional treatment sessions. For sessions in the biofeedback treatment condition, a black circle represents performance on the pre-treatment probe measure, and a red star represents performance on the post-treatment probe. In the traditional treatmnet condition, a blue square represents accuracy on the pre-treatment probe, and a green triangle represents performance on the post-treatment probe. The y-axis represents $\hat{p}_{correct}$ aggregated across all vocalic /r/ items within a session; that is, the total number of "correct /r/" ratings as a percentage of the total number of ratings collected. Thus, the distance between the two probes in a session provide an index of the participant's progress (or lack thereof) during that treatment session. Finally, a dashed horizontal line tracks the participant's mean $\hat{p}_{correct}$ from the baseline interval, so that subsequent scores can be compared to the baseline mean. 

The mean number of probe words on which $\hat{p}_{correct}$ scores are based was `r round(mPREPOST, digits=2)` (SD = `r round(sdPREPOST, digits=2)`) for pre- and post-treatment probes and `r mBLMN` (SD = `r sdBLMN`) for baseline and maintenance probes. The number of ratings collected in connection with a given probe session (i.e., the denominator in $\hat{p}_{correct}$) was roughly nine times the number of items in that probe and often was larger.

For convenience, the single-subject graphs have been grouped into three sets of 3-4 participants who demonstrated broadly similar patterns of response to treatment. Within each group, participants are ordered by increasing length of the baseline phase. Figure 2 depicts four participants for whom visual inspection provided strong evidence of a response to at least one type of treatment, and Figure 3 shows three participants for whom visual inspection provided moderate support of a response to treatment. Finally, Figure 3 shows four participants who showed no reliable evidence of a response to treatment. The participants in each group are discussed in detail below. All participants were judged to demonstrate a sufficiently low level of baseline variability, defined as <10% mean session-to-session variability across the baseline phase. The greatest mean session-to-session variability was observed in participants Ella (`r round(mean_session_to_session_change_5[1], digits=2)` percentage points), Landon (`r round(mean_session_to_session_change_4[4], digits=2)` percentage points), and Aiden (`r round(mean_session_to_session_change_3[1], digits=2)` percentage points). There were no outlier baseline sessions, defined as a session whose accuracy fell more than 2 standard deviations from the mean accuracy across the baseline phase for a given participant. Visual inspection raised questions of a possible rising trend during the baseline phase for participants Aiden and Ella. In Aiden's case, the first data point was particularly low, while data points 2 and 3 show a higher but stable level of accuracy. Aiden's performance on pre- and post-treatment probes in the first treatment session was virtually identical to the second and third baseline sessions, suggesting that these data points can be considered a stable and accurate reflection of his pre-treatment accuracy. In Ella's case, the last three points of the baseline phase form a rising trend that terminates slightly above her mean accuracy across the baseline phase. However, once treatment was initiated, her accuracy in pre-treatment probes remained steady across the next three sessions, whereas post-treatment probe measures showed substantially increased accuracy. In subsequent sessions, both pre- and post-treatment probes showed elevated accuracy. This pattern strongly suggests that the observed gains can be attributed to the application of treatment. In sum, all participants were judged to demonstrate sufficiently stable baselines to serve as the basis for an evaluation of the effects of treatment. 

Figure 2 shows four participants for whom visual inspection offered strong evidence of a response to at least one type of treatment. Visual inspection of data from `r paste(demog$age_enrollment_years[demog$subject=="Aiden"], demog$age_enrollment_months[demog$subject=="Aiden"], sep=";")` year-old Aiden shows a large change in level between the baseline phase and all subsequent phases of treatment, with minimal overlap between observations in the baseline phase and any subsequent phase. This change occurred immediately after the initiation of treatment. Aiden's progress in the first phase, which featured traditional articulatory treatment, yielded a large ES~Phase1~ of `r data3$ESPhase1[data3$subject=="Aiden"]`. His performance declined to some extent in the second phase, which featured biofeedback treatment, yielding an *ES~Phase2~* of `r data3$ESPhase2[data3$subject=="Aiden"]` from midpoint to maintenance. However, his performance still remained substantially above baseline levels, with a final *ES~All~* of `r data3short[1,10]`. 

Ella, age `r paste(demog$age_enrollment_years[demog$subject=="Emma"], demog$age_enrollment_months[demog$subject=="Emma"], sep=";")`, also showed a sizable change in level between the baseline phase and all subsequent phases of the study. This change was evident in post-treatment word probes within the first three sessions of treatment; from the fourth session on, there was virtually no overlap of data points with the baseline phase. The first phase, which featured biofeedback treatment, yielded an *ES~Phase1~* of `r data3$ESPhase1[data3$subject=="Ella"]`. Ella's gains remained mostly stable through the second phase of treatment and the maintenance period, yielding an *ES~All~* of `r data3$ESall[data3$subject=="Ella"]`. Overlap with the baseline phase was minimal from the midpoint session on. 
Participants Landon, age `r paste(demog$age_enrollment_years[demog$subject=="Liam"], demog$age_enrollment_months[demog$subject=="Liam"], sep=";")`, and Mason, age `r paste(demog$age_enrollment_years[demog$subject=="Madison"], demog$age_enrollment_months[demog$subject=="Madison"], sep=";")`, exhibited similar trajectories of progress, although Mason showed higher overall accuracy throughout the study. Like Ella, both boys began in the biofeedback treatment condition and began to show gains within the first three sessions of treatment; they sustained their gains during midpoint probes and made additional improvements in the second phase of treatment. They likewise showed no overlap between the baseline phase and data points in the midpoint phase, second phase of treatment, or maintenance phase. In Mason's case, there also was very little overlap between the baseline phase and the first phase of treatment. For both boys, a larger effect size was calculated for the first phase of treatment, in which biofeedback was provided, although this could be attributed to a ceiling effect in Mason's case. Large overall effect sizes of `r data3$ESall[data3$subject=="Landon"]` and `r data3$ESall[data3$subject=="Mason"]` were observed for Landon and Mason, respectively.

```{r, echo=FALSE, fig.width=7, fig.height=5,message=FALSE, warning=FALSE,strip.white=TRUE}
#################################################################
#FIGURE 2: POSITIVE EFFECT SIZES
#################################################################
#Read in data
data <- read.csv("clean_data.csv")
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)
#Need to re-set ordered factors
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   
#change psuedonyms to pseudo-pseudonyms
data$originalpseudonym <- data$subject
data$subject <- mapvalues(data$originalpseudonym, from = c("Adrian", "Brooklyn", "Connor", "Emily", 
                                                           "Emma", "Gabriel",  "Hailey", "Hannah", 
                                                           "Jack", "Liam", "Madison"), 
                          to = c("Aiden", "Bryce", "Cooper", "Erica", 
                                 "Ella", "Gregory",  "Holly", "Harper", 
                                 "Jason", "Landon", "Mason"))

#Subset to appropriate group of children
data <- droplevels(filter(data, subject=="Aiden"|subject=="Landon"|subject=="Ella"|subject=="Mason"))
data$subject = ordered(data$subject, levels= c("Aiden","Landon","Ella","Mason"))


#Specs for plotting
par(mfrow=c(4,1))
par(mar = c(4, 4, 1.5, 1.5))
par(xpd=FALSE)

#Loop through participants
Children <- levels(data$subject)
for (i in seq_along(Children)){
  
  child <- droplevels(data[data$subject==Children[i],])
  numerical=c(1:length(levels(child$session)))
  minus <- length(numerical) - 2
  labels = levels(child$session)
  label = unique(child$subject)
  
  BL <- droplevels(subset(child, sessiontype=="BL"))
  nbl <- length(levels(BL$session))
  
  bl1_sum <- tapply(BL$correct, BL$session, sum, na.rm=TRUE)
  bl1_total <- tapply(BL$total, BL$session, sum, na.rm=TRUE)
  bl1_perc <- bl1_sum*100/bl1_total
  bl1_m <- mean(bl1_perc)
  
  #Plot Treated Targets
  ###NB name "BF" here is a holdover from cohort 1--
  ###both BF AND TRAD sessions are included in these plots
  #BF Pre
  BF <- subset(child, child$condition=="BF"|child$condition=="PROBE")
  BF_pre <- subset(BF, BF$prepost=="Pre"|BF$prepost=="PROBE")
  BF_pre_mean <- tapply(BF_pre$mean, BF_pre$session, mean)
  BF_pre_correct <- tapply(BF_pre$correct, BF_pre$session, sum)
  BF_pre_total <- tapply(BF_pre$total, BF_pre$session, sum)
  BF_pre_percent <- BF_pre_correct*100/BF_pre_total
  
  #BF Post
  BF_post <- subset(BF, BF$prepost=="Post")
  BF_post_mean <- tapply(BF_post$mean, BF_post$session, mean)
  BF_post_correct <- tapply(BF_post$correct, BF_post$session, sum)
  BF_post_total <- tapply(BF_post$total, BF_post$session, sum)
  BF_post_percent <- BF_post_correct*100/BF_post_total
  
  plot(numerical, BF_pre_percent, 
       main = label,
       xaxt="n", xlab = NA, ylab = NA, ylim = c(0, 100))
  axis(1, at=numerical, labels=labels, cex.axis = 1.25)
  mtext(side = 1, "Session", line = 2.5, cex = .75)
  mtext(side = 2, expression(hat(p)), line = 2, cex = .75)
  #Plot baseline mean
  yline(bl1_m, lty=2)
  
  points(numerical+.2, BF_post_percent,  pch = 8, col = "red", lty=2) 
  
  #Set points for shading BL, MP, and MN regions
  endBL <- nbl + .5
  beginMP <- endBL + 10
  endMP <- beginMP + 3
  beginMN <- endMP + 10
  endMN <- beginMN + 3.6
  color <- rgb(190, 190, 190, alpha=80, maxColorValue=255)
  rect(xleft=0.0-1, xright=endBL, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMP, xright=endMP, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMN, xright=endMN, ybottom=-4, ytop=106, density=100, 
       col=color)
  
  #Plot TRAD
  #TRAD Pre
  TRAD_pre <- subset(child, child$condition=="Trad"&child$prepost=="Pre")
  TRAD_pre_mean <- tapply(TRAD_pre$mean, TRAD_pre$session, mean)
  TRAD_pre_correct <- tapply(TRAD_pre$correct, TRAD_pre$session, sum)
  TRAD_pre_total <- tapply(TRAD_pre$total, TRAD_pre$session, sum)
  TRAD_pre_percent <- TRAD_pre_correct*100/TRAD_pre_total
  #TRAD Post
  TRAD_post <- subset(child, child$condition=="Trad"&child$prepost=="Post")
  TRAD_post_mean <- tapply(TRAD_post$mean, TRAD_post$session, mean)
  TRAD_post_correct <- tapply(TRAD_post$correct, TRAD_post$session, sum)
  TRAD_post_total <- tapply(TRAD_post$total, TRAD_post$session, sum)
  TRAD_post_percent <- TRAD_post_correct*100/TRAD_post_total
  
  #Plot points
  points(numerical, TRAD_pre_percent,  pch = 12, col = "blue", lty=2) 
  points(numerical+.2, TRAD_post_percent,  pch = 6, col = "green", lty=2) 

  #*Place a legend based on mean rating of MN sessions*
  ifelse(mean(rev(BF_pre_percent)[1:3]) <= 50, 
         legend("topright",cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,8,12,6), col=c("black","red", "blue","green"), bg = "white"), 
         legend("bottomright" ,cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,8,12,6), col=c("black","red", "blue","green"), bg = "white"))
}

```

**Figure 2. Longitudinal plots of $\hat{p}_{correct}$ for participants with large positive effect sizes. Dashed line represents mean across baseline sessions. BL = Baseline, Tx = Treatment, MN = Maintenance.**

Figure 3 shows three participants for whom visual inspection offered moderate evidence of a response to at least one type of treatment. Erica, age `r paste(demog$age_enrollment_years[demog$subject=="Emily"], demog$age_enrollment_months[demog$subject=="Emily"], sep=";")`, showed no visual evidence of improvement in the first phase, which featured traditional treatment. (An *ES~Phase1~* of `r data3$ESPhase1[data3$subject=="Erica"]` was computed for her, but given that the raw difference in means was only `r data3$mp1_m[data3$subject=="Erica"]-data3$bl1_m[data3$subject=="Erica"]`, this was judged to be an artifact of low variance during the baseline phase.) During the second phase of treatment, Erica showed a change in trend from a stable near-zero level of accuracy to a small but consistent increase. This effect is ambiguous to interpret, since it emerged only in the last three sessions of the study and thus could reflect a cumulative effect of treatment over the preceding two months. Interestingly, the rising trend that Erica exhibited in her last three sessions of treatment continued into the maintenance phase, suggesting that ongoing generalization gains might be anticipated. Her final effect size (*ES~All~*) of `r data3$ESall[data3$subject=="Erica"]` reflected robust overall gains, although her scores in the maintenance phase remained well below ceiling-level accuracy.

Participant Jason, age `r paste(demog$age_enrollment_years[demog$subject=="Jack"], demog$age_enrollment_months[demog$subject=="Jack"], sep=";")`, showed a trajectory that was in some ways a mirror image of Erica's. Both visual inspection and effect size showed no meaningful change during the first phase of treatment, which featured biofeedback. He also showed no change throughout most of the second treatment phase, but in the final few sessions, his perceptually rated accuracy took on a distinct upward slope. Unlike Erica, his gains tended to affect post-test but not pre-test probes, and accuracy was not sustained throughout the maintenance period. This suggests more short-term learning that was not yet robustly transfering to other contexts. Accordingly, the effect sizes calculated using midpoint and maintenance probe data suggested a weaker effect of treatment than visual inspection of within-treatment data would suggest (*ES~Phase1~* `r data3$ESPhase1[data3$subject=="Jason"]`; *ES~Phase2~* `r data3$ESPhase2[data3$subject=="Jason"]`; *ES~All~* `r data3$ESall[data3$subject=="Jason"]`). 

Participant Gregory, age `r paste(demog$age_enrollment_years[demog$subject=="Gabriel"], demog$age_enrollment_months[demog$subject=="Gabriel"], sep=";")`, showed a small increase in the perceptually rated accuracy of rhotics produced during Phase 1, followed by a slightly larger increase during Phase 2. Ongoing overlap in data points between baseline and treatment phases prevents us from attaching a strong interpretation to these data, and gains were minimally sustained into the midpoint and maintenance probe intervals. All three effect sizes computed for Gregory fell short of the threshold to be considered clinically significant (*ES~Phase1~* `r data3$ESPhase1[data3$subject=="Gregory"]`; *ES~Phase2~* `r data3$ESPhase2[data3$subject=="Gregory"]`; *ES~All~* `r data3$ESall[data3$subject=="Gregory"]`). On the other hand, Gregory's accuracy during both phases of treatment was much more variable than at baseline. This suggested that he was engaging some degree of exploration of new strategies for rhotic production, although he had not yet stabilized a production pattern that would reliably yield a perceptually accurate rhotic sound.

```{r, echo=FALSE, fig.width=7, fig.height=5,message=FALSE, warning=FALSE}
#################################################################
#FIGURE 3: SMALL POSITIVE EFFECT SIZES
#################################################################
#Read in data
data <- read.csv("clean_data.csv")
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)
#Need to re-set ordered factors
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   
#change psuedonyms to pseudo-pseudonyms
data$originalpseudonym <- data$subject
data$subject <- mapvalues(data$originalpseudonym, from = c("Adrian", "Brooklyn", "Connor", "Emily", 
                                                           "Emma", "Gabriel",  "Hailey", "Hannah", 
                                                           "Jack", "Liam", "Madison"), 
                          to = c("Aiden", "Bryce", "Cooper", "Erica", 
                                 "Ella", "Gregory",  "Holly", "Harper", 
                                 "Jason", "Landon", "Mason"))

#Subset to appropriate group of children
data <- droplevels(filter(data, subject=="Erica"|subject=="Jason"|subject=="Gregory"))
data$subject = ordered(data$subject, levels= c("Erica","Gregory","Jason"))

#Specs for plotting
par(mfrow=c(4,1))
par(mar = c(4, 4, 1.5, 1.5))
par(xpd=FALSE)

#Loop through participants
Children <- levels(data$subject)
for (i in seq_along(Children)){
  
  child <- droplevels(data[data$subject==Children[i],])
  numerical=c(1:length(levels(child$session)))
  minus <- length(numerical) - 2
  labels = levels(child$session)
  label = unique(child$subject)
  
  BL <- droplevels(subset(child, sessiontype=="BL"))
  nbl <- length(levels(BL$session))
  
  bl1_sum <- tapply(BL$correct, BL$session, sum, na.rm=TRUE)
  bl1_total <- tapply(BL$total, BL$session, sum, na.rm=TRUE)
  bl1_perc <- bl1_sum*100/bl1_total
  bl1_m <- mean(bl1_perc)
  
  #Plot Treated Targets
  ###NB name "BF" here is a holdover from cohort 1--
  ###both BF AND TRAD sessions are included in these plots
  #BF Pre
  BF <- subset(child, child$condition=="BF"|child$condition=="PROBE")
  BF_pre <- subset(BF, BF$prepost=="Pre"|BF$prepost=="PROBE")
  BF_pre_mean <- tapply(BF_pre$mean, BF_pre$session, mean)
  BF_pre_correct <- tapply(BF_pre$correct, BF_pre$session, sum)
  BF_pre_total <- tapply(BF_pre$total, BF_pre$session, sum)
  BF_pre_percent <- BF_pre_correct*100/BF_pre_total
  
  #BF Post
  BF_post <- subset(BF, BF$prepost=="Post")
  BF_post_mean <- tapply(BF_post$mean, BF_post$session, mean)
  BF_post_correct <- tapply(BF_post$correct, BF_post$session, sum)
  BF_post_total <- tapply(BF_post$total, BF_post$session, sum)
  BF_post_percent <- BF_post_correct*100/BF_post_total
  
  plot(numerical, BF_pre_percent, 
       main = label,
       xaxt="n", xlab = NA, ylab = NA, ylim = c(0, 100))
  axis(1, at=numerical, labels=labels, cex.axis = 1.25)
  mtext(side = 1, "Session", line = 2.5, cex = .75)
  mtext(side = 2, expression(hat(p)), line = 2, cex = .75)

  #Plot baseline mean
  yline(bl1_m, lty=2)
  
  
  points(numerical+.2, BF_post_percent,  pch = 8, col = "red", lty=2) 
  
  #Set points for shading BL, MP, and MN regions
  endBL <- nbl + .5
  beginMP <- endBL + 10
  endMP <- beginMP + 3
  beginMN <- endMP + 10
  endMN <- beginMN + 3.6
  color <- rgb(190, 190, 190, alpha=80, maxColorValue=255)
  rect(xleft=0.0-1, xright=endBL, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMP, xright=endMP, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMN, xright=endMN, ybottom=-4, ytop=106, density=100, 
       col=color)
  
  #Plot TRAD
  #TRAD Pre
  TRAD_pre <- subset(child, child$condition=="Trad"&child$prepost=="Pre")
  TRAD_pre_mean <- tapply(TRAD_pre$mean, TRAD_pre$session, mean)
  TRAD_pre_correct <- tapply(TRAD_pre$correct, TRAD_pre$session, sum)
  TRAD_pre_total <- tapply(TRAD_pre$total, TRAD_pre$session, sum)
  TRAD_pre_percent <- TRAD_pre_correct*100/TRAD_pre_total
  #TRAD Post
  TRAD_post <- subset(child, child$condition=="Trad"&child$prepost=="Post")
  TRAD_post_mean <- tapply(TRAD_post$mean, TRAD_post$session, mean)
  TRAD_post_correct <- tapply(TRAD_post$correct, TRAD_post$session, sum)
  TRAD_post_total <- tapply(TRAD_post$total, TRAD_post$session, sum)
  TRAD_post_percent <- TRAD_post_correct*100/TRAD_post_total
  
  #Plot points
  points(numerical, TRAD_pre_percent,  pch = 12, col = "blue", lty=2) 
  points(numerical+.2, TRAD_post_percent,  pch = 6, col = "green", lty=2) 

  #*Place a legend based on mean rating of MN sessions*
  ifelse(mean(rev(BF_pre_percent)[1:3]) <= 50, 
         legend("topright",cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,8,12,6), col=c("black","red", "blue","green"), bg = "white"), 
         legend("bottomright" ,cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,8,12,6), col=c("black","red", "blue","green"), bg = "white"))
}

```

**Figure 3. Longitudinal plots of $\hat{p}_{correct}$ for participants with small positive effect sizes. Dashed line represents mean across baseline sessions. BL = Baseline, Tx = Treatment, MN = Maintenance.**

Finally, Figure 4 depicts the four participants for whom visual inspection of generalization probe data yielded no significant evidence of a response to either type of treatment. Three of these participants (Bryce, Holly, and Harper) began treatment in the traditional treatment condition, while one participant (Cooper) received treatment in the opposite order. Across all of these participants, visual inspection of perceptual rating data yields a consistent picture of minimal change across all phases of the study. Effect sizes are generally in accordance with visual inspection; an exception is Cooper's *ES~Phase1~* of `r formatC(data3$ESPhase1[data3$subject=="Cooper"], format='f', digits=1)`, but this value is inflated by minimal variance during the baseline phase. Note also that most participants in this group had near-zero perceptual accuracy ratings at baseline, contrasting with the more intermediate accuracy ratings given to participants in the other groups; we return to this topic in the discussion section.


```{r, echo=FALSE, fig.width=7, fig.height=5, message=FALSE, warning=FALSE}
#################################################################
#FIGURE 3: NULL EFFECT SIZES
#################################################################
#Read in data
data <- read.csv("clean_data.csv")
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)
#Need to re-set ordered factors
data$session = ordered(data$session, levels = c("BL1","BL2","BL3","BL4","BL5","TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                                "MP1","MP2","MP3","TX11","TX12",
                                                "TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20","MN1","MN2","MN3"))   
#change psuedonyms to pseudo-pseudonyms
data$originalpseudonym <- data$subject
data$subject <- mapvalues(data$originalpseudonym, from = c("Adrian", "Brooklyn", "Connor", "Emily", 
                                                           "Emma", "Gabriel",  "Hailey", "Hannah", 
                                                           "Jack", "Liam", "Madison"), 
                          to = c("Aiden", "Bryce", "Cooper", "Erica", 
                                 "Ella", "Gregory",  "Holly", "Harper", 
                                 "Jason", "Landon", "Mason"))

#Subset to appropriate group of children
data <- droplevels(filter(data, subject=="Bryce"|subject=="Holly"|subject=="Cooper"|subject=="Harper"))
data$subject = ordered(data$subject, levels= c("Bryce","Holly","Harper", "Cooper"))


#Specs for plotting
par(mfrow=c(4,1))
par(mar = c(4, 4, 1.5, 1.5))
par(xpd=FALSE)

#Loop through participants
Children <- levels(data$subject)
for (i in seq_along(Children)){
  
  child <- droplevels(data[data$subject==Children[i],])
  numerical=c(1:length(levels(child$session)))
  minus <- length(numerical) - 2
  labels = levels(child$session)
  label = unique(child$subject)
  
  BL <- droplevels(subset(child, sessiontype=="BL"))
  nbl <- length(levels(BL$session))
  
  bl1_sum <- tapply(BL$correct, BL$session, sum, na.rm=TRUE)
  bl1_total <- tapply(BL$total, BL$session, sum, na.rm=TRUE)
  bl1_perc <- bl1_sum*100/bl1_total
  bl1_m <- mean(bl1_perc)
  
  #Plot Treated Targets
  ###NB name "BF" here is a holdover from cohort 1--
  ###both BF AND TRAD sessions are included in these plots
  #BF Pre
  BF <- subset(child, child$condition=="BF"|child$condition=="PROBE")
  BF_pre <- subset(BF, BF$prepost=="Pre"|BF$prepost=="PROBE")
  BF_pre_mean <- tapply(BF_pre$mean, BF_pre$session, mean)
  BF_pre_correct <- tapply(BF_pre$correct, BF_pre$session, sum)
  BF_pre_total <- tapply(BF_pre$total, BF_pre$session, sum)
  BF_pre_percent <- BF_pre_correct*100/BF_pre_total
  
  #BF Post
  BF_post <- subset(BF, BF$prepost=="Post")
  BF_post_mean <- tapply(BF_post$mean, BF_post$session, mean)
  BF_post_correct <- tapply(BF_post$correct, BF_post$session, sum)
  BF_post_total <- tapply(BF_post$total, BF_post$session, sum)
  BF_post_percent <- BF_post_correct*100/BF_post_total
  
  plot(numerical, BF_pre_percent, 
       main = label,
       xaxt="n", xlab = NA, ylab = NA, ylim = c(0, 100))
  axis(1, at=numerical, labels=labels, cex.axis = 1.25)
  mtext(side = 1, "Session", line = 2.5, cex = .75)
  mtext(side = 2, expression(hat(p)), line = 2, cex = .75)
  #Plot baseline mean
  yline(bl1_m, lty=2)
  
  points(numerical+.2, BF_post_percent,  pch = 8, col = "red", lty=2) 
  
  #Set points for shading BL, MP, and MN regions
  endBL <- nbl + .5
  beginMP <- endBL + 10
  endMP <- beginMP + 3
  beginMN <- endMP + 10
  endMN <- beginMN + 3.6
  color <- rgb(190, 190, 190, alpha=80, maxColorValue=255)
  rect(xleft=0.0-1, xright=endBL, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMP, xright=endMP, ybottom=-4, ytop=106, density=100, 
       col=color)
  rect(xleft=beginMN, xright=endMN, ybottom=-4, ytop=106, density=100, 
       col=color)
  
  #Plot TRAD
  #TRAD Pre
  TRAD_pre <- subset(child, child$condition=="Trad"&child$prepost=="Pre")
  TRAD_pre_mean <- tapply(TRAD_pre$mean, TRAD_pre$session, mean)
  TRAD_pre_correct <- tapply(TRAD_pre$correct, TRAD_pre$session, sum)
  TRAD_pre_total <- tapply(TRAD_pre$total, TRAD_pre$session, sum)
  TRAD_pre_percent <- TRAD_pre_correct*100/TRAD_pre_total
  #TRAD Post
  TRAD_post <- subset(child, child$condition=="Trad"&child$prepost=="Post")
  TRAD_post_mean <- tapply(TRAD_post$mean, TRAD_post$session, mean)
  TRAD_post_correct <- tapply(TRAD_post$correct, TRAD_post$session, sum)
  TRAD_post_total <- tapply(TRAD_post$total, TRAD_post$session, sum)
  TRAD_post_percent <- TRAD_post_correct*100/TRAD_post_total
  
  #Plot points
  points(numerical, TRAD_pre_percent,  pch = 12, col = "blue", lty=2) 
  points(numerical+.2, TRAD_post_percent,  pch = 6, col = "green", lty=2) 

  #*Place a legend based on mean rating of MN sessions*
  ifelse(mean(rev(BF_pre_percent)[1:3]) <= 50, 
         legend("topright",cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,8,12,6), col=c("black","red", "blue","green"), bg = "white"), 
         legend("bottomright" ,cex=.9, legend = c("Pre BF", "Post BF","Pre Trad", "Post Trad"), 
                pch = c(1,8,12,6), col=c("black","red", "blue","green"), bg = "white"))
}

```

**Figure 4. Longitudinal plots of $\hat{p}_{correct}$ for participants with null or negative effect size. Dashed line represents mean across baseline sessions. BL = Baseline, Tx = Treatment, MN = Maintenance.**

##Across-subjects comparisons: Effect sizes
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=5, fig.width=7}
#Read in ES data
ESdata <- data3
#str(data)

#Plots of effect sizes

#Is there a condition effect? Boxplot depicting BF phase across participants, boxplot depicting TRAD phase across participants
phasedata <- gather(ESdata,Type, ES, c(ES_TRAD, ES_BF))

phasedata$Condition <- mapvalues(phasedata$Type, from = c("ES_BF", "ES_TRAD"), 
                                     to = c("Biofeedback", "Traditional"))

p1 <- qplot(data=phasedata, x=Condition, y=ES, fill = Condition, geom="boxplot", 
            main = "(A) Effect Sizes by Treatment Type", 
            xlab = "Treatment Type", ylab = "Effect Size", show_guide = FALSE) +
            scale_fill_manual(values = c("lightcoral", "cyan3"))

#boxplot(phasedata$BF_advantage)
p1 <- p1 + theme(plot.title = element_text(size = rel(1.5))) + 
    theme(axis.title.y = element_text(size = rel(1.5))) + 
    theme(axis.title.x = element_text(size = rel(1.5))) +
    theme(axis.text = element_text(size = rel(1.5)))

#Is there an order effect? Boxplot depicting ES~Phase1~ across participants, boxplot depicting ES~Phase2~ across participants
#boxplot depicting difference between ES~Phase1~ and ES~Phase2~ across participants.
orderdata <- gather(ESdata,tx_Order, ES, c(ESPhase1, ESPhase2))
#head(phasedata)

orderdata$tx_Order_plot <- mapvalues(orderdata$tx_Order, from = c("ESPhase1", "ESPhase2"), 
                          to = c("Phase 1", "Phase 2"))

p2 <- qplot(data=orderdata, x=tx_Order_plot, y=ES, fill = tx_Order_plot, geom="boxplot", 
            main = "(B) Effect Sizes by Phase Order",
            xlab = "Treatment Order", ylab = "Effect Size", show_guide = FALSE) +
            scale_fill_manual(values = c("lightcoral", "cyan3"))

#boxplot(phasedata$order_effect)
p2 <- p2 + theme(plot.title = element_text(size = rel(1.5))) + 
    theme(axis.title.y = element_text(size = rel(1.5))) + 
    theme(axis.title.x = element_text(size = rel(1.5))) +
    theme(axis.text = element_text(size = rel(1.5)))

both <- gather(ESdata, tx_Order, ES, c(ESPhase1, ESPhase2))
#head(phasedata)

phasedata$tx_order_plot <- mapvalues(phasedata$tx_order, from = c("BF_TRAD", "TRAD_BF"), 
                          to = c("BF-first", "Traditional-first"))

#phasedata <- phasedata[order(phasedata$tx_order_plot, decreasing = TRUE), ]
phasedata$tx_order_plot = ordered(phasedata$tx_order_plot, levels = c("BF-first","Traditional-first"))

p3 <- qplot(data = phasedata, x = tx_order_plot, y = ES, fill = Condition, geom = "boxplot",
            main = "Effect Sizes by Condition and Treatment Order", 
            xlab = "Treatment Order", ylab = "Effect Size") +
            scale_fill_manual(values = c("lightcoral", "cyan3"))

#boxplot(phasedata$order_effect)
```

Although the primary focus of this single-subject experimental study is on within-subject changes, the counterbalanced design makes it possible to explore between-subjects effects as well. The boxplots in Figures 5-6 show the distribution of effect sizes observed when the data are partitioned in different ways. In Figure 5a, effect sizes associated with biofeedback treatment phases (*ES~BF~*) are compared against effect sizes from traditional treatment phases (*ES~Trad~*), independent of the order in which the two types of treatment were delivered. Figure 5b examines a possible order effect, comparing the distribution of *ES~Phase1~* versus *ES~Phase2~*, independent of the type of treatment delivered in each phase. Finally, Figure 6 considers a possible interaction between treatment type and order of treatment delivery: participants are partitioned into those who received biofeedback first versus traditional treatment first, and the distribution of effect sizes observed in each treatment condition is plotted. 

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
grid.arrange(p1, p2, ncol=2)
```

**Figure 5. Boxplots depicting the distribution of effect sizes observed in connection with (A) biofeedback versus traditional treatment, independent of phase order; (B) phase 1 versus phase 2 of treatment, independent of treatment type.**

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
p3 + theme(plot.title = element_text(size = rel(1.5))) + 
    theme(axis.title.y = element_text(size = rel(1.5))) + 
    theme(axis.title.x = element_text(size = rel(1.5))) + 
    theme(legend.text = element_text(size = rel(1.5))) + 
    theme(legend.title = element_text(size = rel(1.5))) +
    theme(axis.text = element_text(size = rel(1.5)))
```

**Figure 6. Boxplots depicting the distribution of effect sizes observed in connection with biofeedback versus traditional treatment when biofeedback treatment was provided first, versus the opposite order.**

Figure 5a shows that the effect size distributions observed in biofeedback versus traditional phases of treatment are extensively overlapped and have very similar median values, although the interquartile range extends to somewhat higher effect sizes for biofeedback than traditional treatment. Figure 5b shows that effect sizes observed in the first phase of treatment tended to be larger than the second phase, although again there is considerable overlap between the interquartile ranges for the two distributions. Separation across phases and conditions becomes evident only when we examine the interaction between the two in Figure 6. Effect sizes observed in connection with biofeedback treatment were substantially larger when biofeedback was provided in Phase 1 versus Phase 2. Interestingly, the median effect size observed for traditional treatment was also slightly higher in the biofeedback-first condiiton, although the interquartile ranges overlap almost completely. Due to the small number of data points, hypothesis tests were not conducted on these comparisons of effect sizes across conditions. Instead, the logistic mixed model reported in the next section will examine these effects and their interactions in greater detail.

##Across-subjects comparisons: Mixed logistic model

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
#############################################################
#LOGISTIC MIXED MODEL
#############################################################
#Read in unmerged data
unmergeddata <- read.csv("clean_data_unsummarized.csv")
#str(unmergeddata)
#dim(unmergeddata)

#Now fit logistic regression
#Because we will be comparing phase 1 and phase 2, use only treatment data
dataTX <- droplevels(unmergeddata[unmergeddata$condition!="PROBE",])
#dim(dataTX)
#levels(dataTX$condition)
#Code by order
dataTX$phase <- 0
TRAD1 <- droplevels(subset(dataTX, tx_order=="TRAD_BF"))
TRAD1[which(TRAD1$condition=="Trad"),]$phase <- 1
TRAD1[which(TRAD1$condition=="BF"),]$phase <- 2
#head(TRAD1)
#table(TRAD1$phase)
BF1 <- droplevels(subset(dataTX, tx_order=="BF_TRAD"))
BF1[which(BF1$condition=="BF"),]$phase <- 1
BF1[which(BF1$condition=="Trad"),]$phase <- 2

mydataTX <- rbind(TRAD1, BF1) 
#table(mydataTX$phase)
#str(mydataTX)

#This model, including an interaction between condition and raw phase order, does not converge
#mymodfull <- glmer(response ~ condition*phase + (condition|subject) + (1|Word) + (1|userCode), data=mydataTX, family="binomial")

#Substitute order of treatment application for raw phase
mymod <- glmer(response ~ condition*tx_order + (condition|subject) + (1|Word) + (1|userCode), data=mydataTX, family="binomial")

#summary(mymod)

#Summarize for plotting
sumdataTX <- dataTX %>%
  dplyr::group_by(subject, condition, tx_order) %>%
    dplyr::summarise(sum=sum(response), total=length(response))

sumdataTX$phat <- 100*(sumdataTX$sum/sumdataTX$total)

#head(sumdataTX)
sumdataTX$tx_order_plot <- mapvalues(sumdataTX$tx_order, from = c("BF_TRAD", "TRAD_BF"), 
                          to = c("BF-first", "Traditional-first"))
sumdataTX$Condition <- mapvalues(sumdataTX$condition, from = c("BF", "Trad"), 
                                     to = c("Biofeedback", "Traditional"))

p4 <- qplot(x = tx_order_plot, y = phat, fill = Condition, data = sumdataTX, geom = "boxplot", 
            main = expression(paste(hat(p), ' Accuracy by Treatment Order and Condition')), 
            xlab = "Treatment Order", ylab = expression(hat(p))) +
            scale_fill_manual(values = c("lightcoral", "cyan3"))
p4 + theme(plot.title = element_text(size = rel(1.5))) + 
    theme(axis.title.y = element_text(size = rel(1.5))) + 
    theme(axis.title.x = element_text(size = rel(1.5))) + 
    theme(legend.text = element_text(size = rel(1.5))) + 
    theme(legend.title = element_text(size = rel(1.5))) +
    theme(axis.text = element_text(size = rel(1.5)))

#df to call specific fixed effects in the text
coeff <- round(summary(mymod)$coeff, digits=2)

#df if needing to call specific random slopes/effects in the text
rand <- data.frame(summary(mymod)$varcor) 
rand[4:5] <- round(rand[4:5], digits=2)
```

The effect sizes discussed in the preceding sections reflect participants' long-term or generalization gains in response to treatment. However, recall that some participants made short-term gains that were evident on post-test probes during treatment, but which were not sustained into the midpoint or maintenance phases (see, e.g., Figure 3). To take these gains into consideration, the logistic mixed model was fitted over all data points from pre- and post-treatment probes elicited during the two phases of treatment. For this analysis, we used an uncollapsed data set in which each data point was a single listener's rating of a single token. The binary rating (correct/incorrect) served as the dependent variable. Random intercepts were included to reflect the fact that data points were nested within subjects, items, and raters. Fixed effects including treatment condition (biofeedback versus traditional) and order of treatment delivery (biofeedback-first versus traditional-first) were examined.\footnote{A model with a fixed effect of raw phase order, i.e. phase 1 versus phase 2, did not converge when random by-subject slopes were included. Because the inclusion of random slopes is interpretively important (Barr, Levy, Scheepers, & Tily, 2013), the model with order of treatment delivery was favored over the model using raw phase order.} Model selection was performed using likelihood ratio tests, and only those effects and interactions that yielded a significant difference in likelihood relative to a reduced model were retained. The final model included the interaction between treatment condition and order of treatment delivery, as well as a by-subject random slope for the effect of treatment condition. 
   
In the logistic mixed model described above, treatment condition (TRAD versus BF) was not a significant predictor of rhotic production accuracy (*$\beta$* = `r formatC(coeff[2,1], format='f', digits=2)`, *SE* = `r coeff[2,2]`, *p* = `r coeff[2,4]`), nor was order of treatment delivery (*$\beta$* = `r coeff[3,1]`, *SE* = `r coeff[3,2]`, *p* = `r coeff[3,4]`). However, the interaction between treatment type and treatment order was significant (*$\beta$* = `r coeff[4,1]`, *SE* = `r formatC(coeff[4,2], format='f', digits=2)`, *p* = `r coeff[4,4]`). This interaction can be visualized in Figure 7, which plots accuracy in within-treatment probes (pre- and post-probes) during both biofeedback and traditional treatment conditions; they are pooled across subjects but partitioned by the order of treatment application (BF-first or TRAD-first). Figure 7 shows that the overall highest accuracy was observed during a phase of traditional treatment that came after a phase of biofeedback treatment. The second-highest accuracy was observed in an initial phase of biofeedback treatment. (Figure 7 shows that accuracy scores tended to be higher in the BF-first order than the TRAD-first order, although this effect was not significant.)  Complete regression results are reported in On-line Supplement A. 

#Effect size correlations

```{r, echo=FALSE, fig.width=7, fig.height=2.5,message=FALSE, warning=FALSE}
#############################################################
#CORRELATIONS BETWEEN ES AND INDIVIDUAL SUBJECT PROPERTIES
#############################################################
#Option to run these without Madison, who is an outlier
#hist(data$ESall)
#data <- droplevels(data[data$ESall<20,])

#Correlation between ES~All~ and age
p5 <- qplot(data=ESdata, x=age_months, y=ESall, geom="point")
CorAgeAll <- cor.test(ESdata$age_months, ESdata$ESall, type="spearman")
#NS

#Correlation between ES~All~ and baseline accuracy (participants who start out more accurate tend to gain more?)
p6 <- qplot(data=ESdata, x=bl1_m, y=ESall, geom="point")
CorBLAll <- cor.test(ESdata$bl1_m, ESdata$ESall, type="spearman")
#NS

#Correlation between ES~All~ and perceptual acuity?
p7 <- qplot(data=ESdata, x=ACUITY_F_PRE, y=ESall, geom="point")
CorPercAll <- cor.test(ESdata$ACUITY_F_PRE, ESdata$ESall, type="spearman")
#NS

#Correlation between BF_advantage and perceptual acuity?
p8 <- qplot(data=ESdata, x=ACUITY_F_PRE, y=BF_advantage, geom="point")
CorPercBFA <- cor.test(ESdata$ACUITY_F_PRE, ESdata$ESall, type="spearman")
#NS

#Correlation between ES_all and previous treatment targeting rhotics?
str(ESdata)
p9 <- qplot(data=ESdata, x=years_tx_rhotics, y=ESall, geom="point")
CorPrevTXAll <- cor.test(ESdata$years_tx_rhotics, ESdata$ESall, type="spearman")
#NS

```



```{r, eval=FALSE, echo=FALSE, fig.width=7, fig.height=2.5,message=FALSE, warning=FALSE}
#############################################################
#WITHIN-TREATMENT CHANGE SCORES: OMIT THIS?
#############################################################
data <- read.csv("clean_data.csv")
#dim(data)
#Check that variables are of correct types
#str(data)
data$subject_number <- as.factor(data$subject_number)

#change psuedonyms to pseudo-pseudonyms
data$originalpseudonym <- data$subject
data$subject <- mapvalues(data$originalpseudonym, from = c("Adrian", "Brooklyn", "Connor", "Emily", 
                                                           "Emma", "Gabriel",  "Hailey", "Hannah", 
                                                           "Jack", "Liam", "Madison"), 
                          to = c("Aiden", "Bryce", "Cooper", "Erica", 
                                 "Ella", "Gregory",  "Holly", "Harper", 
                                 "Jason", "Landon", "Mason"))


#This code creates an option to plot only the primary words and exclude generalization words
#You can ignore it if you are including all words

#For within-session, consider only treatment session data
TX <- droplevels(subset(data, sessiontype=="TX"))
ntx <- length(levels(TX$session))

#Need to re-set ordered factors
TX$session = ordered(TX$session, levels = c("TX1","TX2","TX3","TX4","TX5","TX6","TX7","TX8","TX9","TX10",
                                            "TX11","TX12","TX13","TX14","TX15","TX16","TX17","TX18","TX19","TX20"))   
TX$prepost = ordered(TX$prepost, levels= c("Pre","Post"))



#Summarize by subject, session, prepost
#Include condition (BF vs TRAD) and tx_order as grouping factors
#because you want to preserve this info
TX <- TX %>%
  dplyr::group_by(subject, session, prepost, condition, tx_order) %>%
    dplyr::summarise(correct = sum(correct), total = sum(total))
TX$percent <- 100*TX$correct/TX$total
TX <- as.data.frame(TX)

#Calculate within-session differences by subject
#First use spread() to put pre and post side by side
#Get rid of other numeric columns or they will create NA values
TX$correct <-NULL
TX$total <- NULL
TX <- spread(TX, prepost, percent)

#Create a difference column
#Subtract pre from post on assumption that post will be higher
TX$diff <- TX$Post - TX$Pre
#head(TX)

#Visualize the values
par(mar = c(4, 4, 3, 1.5))
#TX$tx_order[1]
#Loop through participants
Children <- levels(TX$subject)
numerical <- 1:length(levels(TX$session))
for (i in seq_along(Children)){
  child <- droplevels(TX[TX$subject==Children[i],])
  condition <- as.character(child$tx_order[1])
  plot(child$session, child$diff, type="o",
       xaxt="n", xlab = "Session", ylab = "Mean rating", main = c(Children[i],condition), ylim = c(-50, 50))
  axis(1, at=numerical,  cex.axis = 1.25)
  xline(10.5, lty=2)
  yline(0, lty=2)
}

#Calculate means for each phase
#Temp option to strike Hannah data due to missing session
#TX <- droplevels(TX[TX$subject!="Hannah",])
#str(TX)

#Code by treatment phase (chronological order; 1 or 2)
TX$phase <- 0
TX[which(TX$session<="TX10"),]$phase <- "1"
TX[which(TX$session>"TX10"),]$phase <- "2"
#TX$unique <- paste0(TX$subject,"_",TX$phase)


#Summarize by phase
TX <- TX %>%
  dplyr::group_by(subject, phase, condition) %>%
    dplyr::summarise(mean=mean(diff))

TX <- as.data.frame(TX)

#Compare mean within-session change for first vs second phase (chronologically)
phase1 <- droplevels(TX[TX$phase==1,])
phase2 <- droplevels(TX[TX$phase==2,])
#mean(phase1$mean)
#sd(phase1$mean)
#mean(phase2$mean)
#sd(phase2$mean)
#t.test(phase1$mean, phase2$mean)
#NS

#Compare mean within-session change for Trad phase vs BF phase 
Trad <- droplevels(TX[TX$condition=="Trad",])
BF <- droplevels(TX[TX$condition=="BF",])
#mean(Trad$mean)
#sd(Trad$mean)
#mean(BF$mean)
#sd(BF$mean)
#Mean is larger for BF than Trad, but highly variable; nonsignificant
#t.test(BF$mean, Trad$mean)
#NS

#I don't know why this boxplot isn't working
#qplot(TX$mean, fill = TX$condition, geom="boxplot")

#Compare Trad vs BF means in a within-subject fashion
TX$phase <- NULL
TX <- TX %>% 
  spread(condition, mean)
#t.test(TX$BF, TX$Trad, paired=TRUE)
#Still definitely NS

```
